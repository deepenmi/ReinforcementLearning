{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenAIGymEnvironment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNUDjIdWS1GLryMjgpRUJLb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepenmi/ReinforcementLearning/blob/master/OpenAIGymEnvironment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0_AO8XVvdCf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9adbf76-43dd-4760-c109-9443d69b2e76"
      },
      "source": [
        "# import OPenAI gym\n",
        "import gym\n",
        "\n",
        "# create the environment\n",
        "env = gym.make('CartPole-v0')\n",
        "\n",
        "# initialize the env\n",
        "env.reset()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.04992686, -0.02330725, -0.03010332, -0.03566853])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0moH4-fQv1R_",
        "colab_type": "text"
      },
      "source": [
        "# Display CartPole"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wanjLK5Zv3me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show a few frames of Cartpole\n",
        "for i in range(100):\n",
        "  # display the env (optional)\n",
        "  # env.reset()\n",
        "  # randomly chose an action from all available actions\n",
        "  action = env.action_space.sample()\n",
        "  # agemt takes an action and intercepts with the env, receiving states, reward, done and info\n",
        "  state, reward, done, info = env.step(action)\n",
        "  # if episode is over reset the env\n",
        "  if done:\n",
        "    env.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i0QWfIrvzyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "5541caa2-81d1-4c0e-c99a-d006e1547a73"
      },
      "source": [
        "print(\"state space is {}\".format(env.observation_space))\n",
        "print(\"action space is {}\".format(env.action_space))\n",
        "print(\"example state  is {}\".format(env.reset()))\n",
        "print(\"example action is {}\".format(env.action_space.sample()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state space is Box(4,)\n",
            "action space is Discrete(2)\n",
            "example state  is [ 0.0101633  -0.01640357  0.01013651  0.0405361 ]\n",
            "example action is 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEHRyx3hxLyP",
        "colab_type": "text"
      },
      "source": [
        "# Reinforcement Learning Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_1idDW7xO_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "d929d2d0-bda7-4f8d-c41a-72b9793d09f6"
      },
      "source": [
        "episodes = 10\n",
        "for ep in range(episodes):\n",
        "  episode_reward = 0\n",
        "  while True:\n",
        "    action = env.action_space.sample()\n",
        "    state, reward, done, info = env.step(action)\n",
        "    episode_reward += reward\n",
        "    if done:\n",
        "      print(\"Episode {} done with reward: {}\".format(ep, episode_reward))\n",
        "      env.reset()\n",
        "      break"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 0 done with reward: 18.0\n",
            "Episode 1 done with reward: 43.0\n",
            "Episode 2 done with reward: 34.0\n",
            "Episode 3 done with reward: 32.0\n",
            "Episode 4 done with reward: 16.0\n",
            "Episode 5 done with reward: 20.0\n",
            "Episode 6 done with reward: 39.0\n",
            "Episode 7 done with reward: 38.0\n",
            "Episode 8 done with reward: 10.0\n",
            "Episode 9 done with reward: 16.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9MWLvOOx9sn",
        "colab_type": "text"
      },
      "source": [
        "# Episodes and Timesteps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VftjscAqyAQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "64f60d4a-c7a3-4f1e-da16-ed816e019859"
      },
      "source": [
        "episodes = 10\n",
        "max_timesteps = 200\n",
        "# run environment for 10 episodes\n",
        "for ep in range(episodes):\n",
        "  timestep = 0\n",
        "  while timestep < max_timesteps:\n",
        "    # randomly chose an action from all available actions\n",
        "    action = env.action_space.sample()\n",
        "    # agent takes an action and interacts with the env, receiving state, reward, done and info\n",
        "    state, reward, done, info = env.step(action)\n",
        "    timestep += 1\n",
        "    # if episode is over the env\n",
        "    if done:\n",
        "      print(\"Episode {} done after {} timesteps\".format(ep, timestep))\n",
        "      env.reset()\n",
        "      break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 0 done after 15 timesteps\n",
            "Episode 1 done after 17 timesteps\n",
            "Episode 2 done after 26 timesteps\n",
            "Episode 3 done after 53 timesteps\n",
            "Episode 4 done after 27 timesteps\n",
            "Episode 5 done after 21 timesteps\n",
            "Episode 6 done after 24 timesteps\n",
            "Episode 7 done after 13 timesteps\n",
            "Episode 8 done after 11 timesteps\n",
            "Episode 9 done after 20 timesteps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB2hpcDKy1cT",
        "colab_type": "text"
      },
      "source": [
        "# Interacting with the environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxcBmKKNxrGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "2d675a94-21a0-40f1-dfc4-923c8c1ea732"
      },
      "source": [
        "episodes = 1\n",
        "max_timesteps = 10\n",
        "\n",
        "for ep in range(episodes):\n",
        "  timestep = 0\n",
        "  while timestep < max_timesteps:\n",
        "    action = env.action_space.sample()\n",
        "    state, rewards, done, info = env.step(action)\n",
        "    timestep += 1\n",
        "    print(\"Timestep {}: agent took action {}\".format(timestep, action))\n",
        "    print(\"Timestep {}: state {}, reward {}, done {}, infor {}\".format(timestep, state, reward, done, info))\n",
        "    # if episode is over reset the env\n",
        "    if done:\n",
        "      env.reset()\n",
        "      break\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Timestep 1: agent took action 1\n",
            "Timestep 1: state [-0.05053909  0.16162688  0.02153713 -0.32041237], reward 1.0, done False, infor {}\n",
            "Timestep 2: agent took action 0\n",
            "Timestep 2: state [-0.04730655 -0.03379506  0.01512888 -0.02101602], reward 1.0, done False, infor {}\n",
            "Timestep 3: agent took action 0\n",
            "Timestep 3: state [-0.04798245 -0.22913067  0.01470856  0.27640159], reward 1.0, done False, infor {}\n",
            "Timestep 4: agent took action 1\n",
            "Timestep 4: state [-0.05256506 -0.03422162  0.02023659 -0.0116062 ], reward 1.0, done False, infor {}\n",
            "Timestep 5: agent took action 0\n",
            "Timestep 5: state [-0.0532495  -0.22962786  0.02000447  0.28739229], reward 1.0, done False, infor {}\n",
            "Timestep 6: agent took action 1\n",
            "Timestep 6: state [-0.05784205 -0.03479681  0.02575231  0.00108512], reward 1.0, done False, infor {}\n",
            "Timestep 7: agent took action 1\n",
            "Timestep 7: state [-0.05853799  0.15994653  0.02577402 -0.28336269], reward 1.0, done False, infor {}\n",
            "Timestep 8: agent took action 1\n",
            "Timestep 8: state [-0.05533906  0.35469156  0.02010676 -0.56780649], reward 1.0, done False, infor {}\n",
            "Timestep 9: agent took action 0\n",
            "Timestep 9: state [-0.04824523  0.15929343  0.00875063 -0.26885755], reward 1.0, done False, infor {}\n",
            "Timestep 10: agent took action 0\n",
            "Timestep 10: state [-0.04505936 -0.0359523   0.00337348  0.02657249], reward 1.0, done False, infor {}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jinX-5a2xK2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}